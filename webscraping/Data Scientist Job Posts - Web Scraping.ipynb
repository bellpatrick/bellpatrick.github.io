{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Scientist Job Posts: Web Scraping\n",
    "\n",
    "The objective of this project is twofold;\n",
    "- 1) build out a tool that can scape several job sites to pull out key competencies + trends for data science roles\n",
    "- 2) use this project as a way to build competency in web scraping and data visualization\n",
    "\n",
    "Even though several people have taken on similar projects, there has not been a strict focus on; 1) remote jobs, 2) current jobs / a tool I can reuse. I've also not seen a lot of EDA + visualization that was super useful for new data scientists to zero in their training on the most marketable skills (at the time).\n",
    "\n",
    "Either way, this will still be a super useful and fun project to build out skills in web scraping and visualization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import time\n",
    "import seaborn as sns\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping\n",
    "\n",
    "The key data we want to collect are:\n",
    "- job title\n",
    "- company name\n",
    "- job summary - note: once we have this extracted, we'll work on EDA and data visulation in sections below\n",
    "\n",
    "For this project, I'll also pull this information out for jobs with titles that contain:\n",
    "- data scientist\n",
    "- analytics\n",
    "- machine learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs = []\n",
    "companies = []\n",
    "summaries = []\n",
    "types = ['data+scientist', 'analytics', 'machine+learning']\n",
    "\n",
    "for i in range (0,2000,10):\n",
    "    #url = \"https://www.indeed.com/jobs?q=data+scientist&l=Remote&start=\" + str(i)\n",
    "    url = \"https://www.indeed.com/jobs?\" + \"q=\" + str(types) + \"&l=Remote\" + \"&start=\" +str(i)\n",
    "    results = requests.get(url+str(types)+str(i))\n",
    "    time.sleep(1)\n",
    "    soup = BeautifulSoup(results.text, \"html.parser\")\n",
    "    for div in soup.find_all(name=\"h2\", attrs={\"class\":\"title\"}):\n",
    "        for a in div.find_all(name=\"a\", attrs={\"data-tn-element\":\"jobTitle\"}):\n",
    "            jobs.append(a[\"title\"])\n",
    "    for div in soup.find_all(name=\"div\", attrs={\"class\":\"sjcl\"}):\n",
    "        company = div.find_all(name=\"a\", attrs={\"data-tn-element\":\"companyName\"})\n",
    "        if len(company) > 0:\n",
    "            for b in company:\n",
    "                companies.append(b.text.strip())\n",
    "        else:\n",
    "            sec_try = div.find_all(name=\"span\", attrs={\"class\":\"company\"})\n",
    "            for span in sec_try:\n",
    "                companies.append(span.text.strip())\n",
    "    sum = soup.findAll(\"div\", attrs={\"class\": \"summary\"})\n",
    "    for sum in sum:\n",
    "        summaries.append(sum.text.strip())\n",
    "    \n",
    "indeed_combined = pd.DataFrame({'title':jobs,\n",
    "                      'company':companies,\n",
    "                      'summary':summaries})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0       Design and build scalable production-ready ana...\n",
      "1       Do you have experience, knowledge or interest ...\n",
      "2       Support and drive analytic efforts around mach...\n",
      "3       Proficiency with statistical analysis tools e....\n",
      "4       2+ years experience with machine learning and ...\n",
      "                              ...                        \n",
      "3006    Partner with a cross-functional team of data s...\n",
      "3007    Proven track record of architecting, developin...\n",
      "3008    Natural Language Processing (NLP) centric role...\n",
      "3009    We offer a generous budget for personal develo...\n",
      "3010    Youâ€™ll get to work with an experienced team of...\n",
      "Name: summary, Length: 3011, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(indeed_combined[\"summary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'indeed_combined' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-9513f3b41c2d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mindeed_combined\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/Volumes/GoogleDrive/My Drive/ml_projects/indeed_combined\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'indeed_combined' is not defined"
     ]
    }
   ],
   "source": [
    "indeed_combined.to_csv(\"/Volumes/GoogleDrive/My Drive/ml_projects/indeed_combined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "Now that we have all the relevant data scaped, let's start digging into the summary section to pull out key competencies for data science roles. For this, I'll be using the NLTK throughout. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepping and Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from string import punctuation\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "indeed_combined = pd.read_csv(\"/Volumes/GoogleDrive/My Drive/ml_projects/indeed_combined\", dtype=str)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "indeed_combined['summary'] = indeed_combined['summary'].dropna() \n",
    "indeed_combined['summary'] = indeed_combined.summary.astype('string')\n",
    "summary = indeed_combined.summary.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing numbers from summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_cleaned = ''.join(c for c in summary if not c.isdigit())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing tags using regex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "summary_cleaned = re.sub('<[^<]+?','',summary_cleaned)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization and Word Frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/patrickbell/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = stopwords.words('english')\n",
    "\n",
    "punctuation = punctuation + '\\n'\n",
    "\n",
    "tokens = nltk.word_tokenize(summary_cleaned)\n",
    "\n",
    "word_frequencies = {}\n",
    "for word in tokens:\n",
    "    if word.lower() not in stop_words:\n",
    "        if word.lower() not in punctuation:\n",
    "            if word not in word_frequencies.keys():\n",
    "                word_frequencies[word] = 1\n",
    "            else:\n",
    "                word_frequencies[word] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking it all out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data : 3005 \n",
      "learning : 2119 \n",
      "experience : 1837 \n",
      "machine : 1455 \n",
      "years : 798 \n",
      "analytics : 643 \n",
      "techniques : 631 \n",
      "statistical : 597 \n",
      "three : 579 \n",
      "science : 561 \n",
      "team : 560 \n",
      "scientists : 401 \n",
      "modeling : 398 \n",
      "least : 398 \n",
      "five : 398 \n",
      "industry : 398 \n",
      "decision : 391 \n",
      "tree : 391 \n",
      "projects : 391 \n",
      "engineers : 382 \n",
      "solutions : 369 \n",
      "get : 362 \n",
      "role : 361 \n",
      "product : 359 \n",
      "work : 352 \n",
      "experienced : 339 \n",
      "using : 279 \n",
      "building : 252 \n",
      "r : 220 \n",
      "testing : 218 \n",
      "python : 218 \n",
      "deep : 211 \n",
      "knowledge : 210 \n",
      "scientist : 202 \n",
      "areas : 201 \n",
      "build : 200 \n",
      "interest : 200 \n",
      "drive : 200 \n",
      "efforts : 200 \n",
      "analysis : 200 \n",
      "tools : 200 \n",
      "applying : 200 \n",
      "hands-on : 200 \n",
      "programming : 200 \n",
      "developing : 200 \n",
      "products : 200 \n",
      "scalable : 199 \n",
      "production-ready : 199 \n",
      "wide : 199 \n",
      "array : 199 \n",
      "methodologies : 199 \n",
      "field : 199 \n",
      "machineâ€¦do : 199 \n",
      "one : 199 \n",
      "following : 199 \n",
      "practical : 199 \n",
      "a/b : 199 \n",
      "websites : 199 \n",
      "feature : 199 \n",
      "engineering : 199 \n",
      "predictiveâ€¦support : 199 \n",
      "analytic : 199 \n",
      "around : 199 \n",
      "innovation : 199 \n",
      "coach : 199 \n",
      "mentor : 199 \n",
      "junior : 199 \n",
      "scientists.proficiency : 199 \n",
      "e.g. : 199 \n",
      "hands : 199 \n",
      "â€¦2+ : 199 \n",
      "predictive : 199 \n",
      "within : 199 \n",
      "large : 199 \n",
      "datasets : 199 \n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "k = Counter(word_frequencies)\n",
    "high = k.most_common(75)\n",
    "\n",
    "for i in high:\n",
    "    print(i[0], \":\", i[1], \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Sentence Scores using Word Frequencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_list = nltk.sent_tokenize(summary_cleaned)\n",
    "sentence_scores = {}\n",
    "for sent in sentence_list:\n",
    "    for word in tokens:\n",
    "        if word in word_frequencies.keys():\n",
    "            if len(sent.split(' ')) < 30:\n",
    "                if sent not in sentence_scores.keys():\n",
    "                    sentence_scores[sent] = word_frequencies[word]\n",
    "                else:\n",
    "                    sentence_scores[sent] += word_frequencies[word]\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conlclussion / Summary\n",
    "- it's not the mots clean summary (runons, etc.)\n",
    "- however, for learning purposes, this was great and gives a decent overview or current hiring trends in data science\n",
    "- when taking a more objective / quantitative view, there isn't a ton of nuance in what is being looked for in data science roles\n",
    "-- 3-5 years experience\n",
    "-- ability to do all aspects (data finding, processing, modeling, etc.)\n",
    "-- machine learning using python and / or R"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "at least three to five years of industry experience in data analytics.cleanse and wrangle student interaction data from our learning platforms. experience on projects applying network science/graph analytics.lead data automation projects to aggregate disparate data sources. d required with concentration on statistics/ machine learning highly preferred.we offer a generous budget for personal development expenses like training courses, conferences, and books. experience with a variety of machine learning techniques (clustering, decision tree learning,â€¦at least three to five years of industry experience in data analytics. enhancing data collection procedures to include information that isâ€¦machine learning for supervised learning. querying and analyzing data using a holistic perspective. experience on projects applying network science/graph analytics.at least three to five years of industry experience in data analytics. exposure to python or r libraries for machine learning.lead data automation projects to aggregate disparate data sources. experience with a variety of machine learning techniques (clustering, decision tree learning,â€¦full cycle of building machine learning solutions,. machine learning, deep learning knowledge and experience.\n"
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "summary_sentences = heapq.nlargest(10, sentence_scores, key=sentence_scores.get)\n",
    "\n",
    "summary = ' '.join(summary_sentences)\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
